{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Пути к файлам и соответствующие названия колонок\n",
    "file_paths = {\n",
    "    # 'bert': '/bert/sim-words5-bert.csv',\n",
    "    'glove': '/glove_python/sim-words_sent_5_glove.csv',\n",
    "    'word2vec': '/word2vec/similar_words_sent_5.csv'\n",
    "}\n",
    "\n",
    "\n",
    "data = {}\n",
    "for model_name, path in file_paths.items():\n",
    "  full_path = \"..\" + path\n",
    "  df = pd.read_csv(full_path)\n",
    "  data[model_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Граф 'glove' содержит 18402 узлов и 9921 рёбер.\n",
      "Граф 'word2vec' содержит 18401 узлов и 86834 рёбер.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from ast import literal_eval\n",
    "\n",
    "graphs = {}\n",
    "for model_name, df in data.items():\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        word = row['Word']\n",
    "        similar_words = row['Most_Similar_Word']\n",
    "        \n",
    "        # Пропускаем пустые списки\n",
    "        if not similar_words or pd.isna(similar_words):\n",
    "            continue\n",
    "        \n",
    "        G.add_node(word)\n",
    "        # Преобразуем строку в список кортежей (если данные в формате строки)\n",
    "        if isinstance(similar_words, str):\n",
    "            try:\n",
    "                similar_words = literal_eval(similar_words)\n",
    "            except (ValueError, SyntaxError):\n",
    "                continue\n",
    "        # Добавляем рёбра в граф\n",
    "        for similar_word, weight in similar_words:\n",
    "            G.add_edge(word, similar_word, weight=weight)\n",
    "    graphs[model_name] = G    \n",
    "    nx.write_gexf(G, f\"{model_name}_graph.gexf\")  # формат GEXF для Gephi\n",
    "    print(f\"Граф '{model_name}' содержит {len(G.nodes)} узлов и {len(G.edges)} рёбер.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: glove\n",
      "Число кластеров (Louvain): 15503\n",
      "Размеры кластеров: [(259, 425), (54, 374), (6827, 248), (258, 214), (329, 214)]\n",
      "Модулярность: 0.460\n",
      "model name: word2vec\n",
      "Число кластеров (Louvain): 5854\n",
      "Размеры кластеров: [(36, 1666), (14, 1543), (65, 1315), (84, 1236), (19, 1103)]\n",
      "Модулярность: 0.625\n"
     ]
    }
   ],
   "source": [
    "from community import community_louvain\n",
    "for model_name, G in graphs.items():\n",
    "  print(f\"model name: {model_name}\")\n",
    "  partition = community_louvain.best_partition(G, weight='weight')\n",
    "  # Кол-во кластеров\n",
    "  num_clusters = max(partition.values()) + 1\n",
    "  print(f\"Число кластеров (Louvain): {num_clusters}\")\n",
    "  \n",
    "  # Размеры кластеров\n",
    "  from collections import Counter\n",
    "  cluster_sizes = Counter(partition.values())\n",
    "  print(f\"Размеры кластеров: {cluster_sizes.most_common(5)}\")  # Топ-5 кластеров\n",
    "\n",
    "  # 3. Модулярность (качество кластеризации)\n",
    "  modularity = community_louvain.modularity(partition, G, weight='weight')\n",
    "  print(f\"Модулярность: {modularity:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
