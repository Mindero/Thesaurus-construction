{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Пути к файлам и соответствующие названия колонок\n",
    "file_paths = {\n",
    "    'bert': '/bert/sim-words5-bert.csv',\n",
    "    'glove': '/glove_python/sim-words10-glove.csv',\n",
    "    'pmi': '/pmi/similar_words_pmi.csv',\n",
    "    'word2vec': '/word2vec/similar_words10.csv'\n",
    "}\n",
    "\n",
    "# Создаем пустой DataFrame с колонкой 'word'\n",
    "data = pd.DataFrame(columns=['word'])\n",
    "\n",
    "# Обрабатываем каждый файл\n",
    "for model_name, path in file_paths.items():\n",
    "    # Читаем CSV-файл\n",
    "    full_path = \"..\" + path\n",
    "    df = pd.read_csv(full_path)\n",
    "    \n",
    "    # Переименовываем колонку Most_Similar_Word в название модели\n",
    "    df = df.rename(columns={'Most_Similar_Word': model_name})\n",
    "    \n",
    "    # Если это первый файл, используем его слова как основу\n",
    "    if data.empty:\n",
    "        data['word'] = df['Word']\n",
    "    \n",
    "    # Добавляем данные в основной DataFrame\n",
    "    data[model_name] = df[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ö(\\x83;¤Ð\\x90;\\x1f\\x05{»{ÔV»¸\\x1e³:qýE;×£v:\\x9a\\x99]9ö(l»×c\\x11;\\x00À\\x8e»®Ç£:ÃõDº\\x85ëzºÍLY»3³öº='",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyedVectors, Word2Vec\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Загрузка эталонной модели\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m thesaurus = \u001b[43mKeyedVectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthesaurus.w2v\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatin1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# thesaurus = Word2Vec.load(\"thesaurus.w2v\", encoding='latin1')\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\scoop\\apps\\python\\3.12.6\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[39m, in \u001b[36mKeyedVectors.load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[39m\n\u001b[32m   1672\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mload_word2vec_format\u001b[39m(\n\u001b[32m   1674\u001b[39m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab=\u001b[38;5;28;01mNone\u001b[39;00m, binary=\u001b[38;5;28;01mFalse\u001b[39;00m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf8\u001b[39m\u001b[33m'\u001b[39m, unicode_errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1675\u001b[39m         limit=\u001b[38;5;28;01mNone\u001b[39;00m, datatype=REAL, no_header=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1676\u001b[39m     ):\n\u001b[32m   1677\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[32m   1678\u001b[39m \n\u001b[32m   1679\u001b[39m \u001b[33;03m    Warnings\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1717\u001b[39m \n\u001b[32m   1718\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1720\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\scoop\\apps\\python\\3.12.6\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2069\u001b[39m, in \u001b[36m_load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[39m\n\u001b[32m   2065\u001b[39m         _word2vec_read_binary(\n\u001b[32m   2066\u001b[39m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[32m   2067\u001b[39m         )\n\u001b[32m   2068\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2069\u001b[39m         \u001b[43m_word2vec_read_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kv.vectors.shape[\u001b[32m0\u001b[39m] != \u001b[38;5;28mlen\u001b[39m(kv):\n\u001b[32m   2071\u001b[39m     logger.info(\n\u001b[32m   2072\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mduplicate words detected, shrinking matrix size from \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2073\u001b[39m         kv.vectors.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mlen\u001b[39m(kv),\n\u001b[32m   2074\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\scoop\\apps\\python\\3.12.6\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1974\u001b[39m, in \u001b[36m_word2vec_read_text\u001b[39m\u001b[34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[39m\n\u001b[32m   1972\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m line == \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1973\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1974\u001b[39m word, weights = \u001b[43m_word2vec_line_to_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1975\u001b[39m _add_word_to_kv(kv, counts, word, weights, vocab_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\scoop\\apps\\python\\3.12.6\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1980\u001b[39m, in \u001b[36m_word2vec_line_to_vector\u001b[39m\u001b[34m(line, datatype, unicode_errors, encoding)\u001b[39m\n\u001b[32m   1978\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_word2vec_line_to_vector\u001b[39m(line, datatype, unicode_errors, encoding):\n\u001b[32m   1979\u001b[39m     parts = utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1980\u001b[39m     word, weights = parts[\u001b[32m0\u001b[39m], [\u001b[43mdatatype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m parts[\u001b[32m1\u001b[39m:]]\n\u001b[32m   1981\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m word, weights\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'ö(\\x83;¤Ð\\x90;\\x1f\\x05{»{ÔV»¸\\x1e³:qýE;×£v:\\x9a\\x99]9ö(l»×c\\x11;\\x00À\\x8e»®Ç£:ÃõDº\\x85ëzºÍLY»3³öº='"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "\n",
    "# Загрузка эталонной модели\n",
    "thesaurus = KeyedVectors.load_word2vec_format(\"thesaurus.w2v\", binary=False, encoding='latin1')\n",
    "# thesaurus = Word2Vec.load(\"thesaurus.w2v\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'1239965 100\\n', b'</s> \\xf6(\\x83;\\xa4\\xd0\\x90;\\x1f\\x05{\\xbb{\\xd4V\\xbb\\xb8\\x1e\\xb3:q\\xfdE;\\xd7\\xa3v:\\x9a\\x99]9\\xf6(l\\xbb\\xd7c\\x11;\\x00\\xc0\\x8e\\xbb\\xae\\xc7\\xa3:\\xc3\\xf5D\\xba\\x85\\xebz\\xba\\xcdLY\\xbb3\\xb3\\xf6\\xba=\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"thesaurus.w2v\", \"rb\") as f:\n",
    "    first_lines = [f.readline() for _ in range(2)]\n",
    "    print(first_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
