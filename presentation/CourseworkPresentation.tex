\documentclass[pdf, intlimits, unicode, S6, presentation]{beamer}
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{minted}
\setminted[text]{fontsize=\small, breaklines=true, style=bw, linenos}

\usetheme{Warsaw}
\usefonttheme[onlysmall]{structurebold}
\usefonttheme[onlymath]{serif}
\setbeamercovered{dynamic}
\setbeamercovered{transparent}
\setbeamerfont{institute}{size=\normalsize}
%\setbeamertemplate{background canvas}[vertical shading][bottom=red!10,top=blue!10]
\setbeamertemplate{theorems}[unnumbered]
\setbeamertemplate{footline}{}
\setbeamertemplate{headline}{}
\setbeamercolor{bluetext_color}{fg=blue}
\newcommand{\bluetext}[1]{{\usebeamercolor[fg]{bluetext_color}#1}}

\usepackage{beamerthemesplit}
\usepackage{dsfont}
\usepackage{pgfplots}

%\usepackage{graphics}

\newcounter{sli}
\newcommand{\slnumber}{\hfill {\color{lightgray} \refstepcounter{sli}\arabic{sli}}}

\title[title]
{Реализация семантического поиска на корпусе новостных документов}
\author{Курсовая работа \\
    студента 351 группы Янченко В.~А.}
\institute{{Саратовский государственный университет} \\
    им.~Н.~Г.~Чернышевского \\[5pt]
Кафедра математической кибернетики\\ и компьютерных наук\\[5pt]
Научный руководитель: доцент, к.~ф.-м.~н. С.~В.~Папшев
}
\date{2025г.}
\begin{document}

% Титульный лист - обязательный слайд
\begin{frame}
    \titlepage
\end{frame}

% Постановка задачи - обязательный слайд
\begin{frame}
    \frametitle{Постановка проблемы и цель \slnumber}
    \large
    Полнотекстовый поиск не улавливает смысловую близость слов, что снижает точность при нечетких запросах. Семантический поиск помогает, но универсальные эмбеддинги не отражают особенности конкретной области, а расширение запроса через общеязыковой тезаурус добавляет слишком общие слова, снижая релевантность результатов.

    \textbf{Цель работы}: разработать систему семантического поиска по корпусу новостных документов с использованием эмбеддингов.
\end{frame}

\begin{frame}
  \frametitle{Корпус новостных документов \slnumber}
  \large
  Были взяты новости СГУ за период с 2007 по 2022 года.
  \begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{data-example.png}
    \caption{Пример представления новостей}
  \end{figure}
  % В качестве корпуса новостных документов были взяты новости СГУ за период с 2007 по 2022 года. Текст новости был обработан. Обработка заключалась в удалении стоп-слов, имен собственных и лемматизации, то есть приведение к начальной форме.
  % На картинке показан пример того, как эти новости представлены. Видим столбец id новости, заголовок, необработанный и обработанный текст.
\end{frame}

\begin{frame}
  \frametitle{Построение моделей на основе корпуса новостных документов \slnumber}
  \large
  Обучены модели:
  \begin{enumerate}
    \item Word2Vec
    \item GloVe
  \end{enumerate}
  Параметры моделей:
  \begin{itemize}
    \item размер получаемых эмбеддингов "--- $300$;
    \item размер контекстного окна "--- $5$;
    \item минимальная частота встречаемости слова "--- $5$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Анализ моделей, построенных на основе корпуса новостных документов \slnumber}
  \large
  % По каждой модели построим тезаурус, тем самым, получим для каждого слова модели набор его синонимов. 

  \begin{table}[!h]
    \centering
    \footnotesize
    \caption{Синонимы для 5 случайных слов для моделей GloVe и Word2Vec}
    \begin{tabular}{|l|l|l|}
      \hline
      \multicolumn{1}{|c|}{\textbf{Word}} & \multicolumn{1}{c|}{\textbf{GloVe}} & \textbf{Word2Vec}                                                                                                                           \\ \hline
      баян                                & аккордеон                           & \begin{tabular}[c]{@{}l@{}}флейта, балалайка, \\ аккордеон, саксофон, \\ ария, барабан, \\ гитара, бас, \\ фортепиано, укулела\end{tabular} \\ \hline
      голод                               & холод                               & \begin{tabular}[c]{@{}l@{}}холод, вражеский, \\ танк, убийство, \\ отважный, наносить, \\ жуткий, фашист\end{tabular}   \\ \hline
      орфография                          & пунктуация                          & -                                                                                                                                           \\ \hline
      внимательность                      & сосредоточенность                   & \begin{tabular}[c]{@{}l@{}}быстрота, \\ коммуникабельность\end{tabular}                                                                     \\ \hline
      альпинизм                           & скалолазание                        & скалолазание                                                                                                                                \\ \hline
    \end{tabular}
  \end{table}
\end{frame}

\begin{frame}
  \frametitle{Анализ моделей, построенных на основе корпуса новостных документов \slnumber}
  \large
  % По каждой модели построим граф, в котором вершиной является слово, а ребро "--- факт того, что слово является близким для рассматриваемого с весом, равным косиносному расстоянию между ними.

  \begin{table}[!ht]
    \centering
    \caption{Сравнительная характеристика графов моделей}
    \begin{tabular}{|l|l|l|}
        \hline
        \multicolumn{1}{|c|}{\textbf{Характеристика}}                                                & \multicolumn{1}{c|}{\textbf{GloVe}} & \textbf{Word2Vec} \\ \hline
        Кол-во вершин                                                                                & 18402                               & 18401             \\ \hline
        Кол-во ребер                                                                                 & 2793                                & 45709             \\ \hline
        Кол-во неизолированных вершин                                                                & 2183                                & 7533              \\ \hline
        \begin{tabular}[c]{@{}l@{}}Кол-во компонент \\ (без учёта изолированных вершин)\end{tabular} & 688                                 & 360               \\ \hline
        Кол-во сообществ                                                                             & 734                                 & 379               \\ \hline
        Модулярность                                                                                 & 0.618                               & 0.612             \\ \hline
    \end{tabular}
    \label{table:graph}
  \end{table}
\end{frame}

\begin{frame}
  \frametitle{Анализу моделей, построенных на основе корпуса новостных документов \slnumber}
  \begin{figure}[!ht]
    \centering
    \small
    \begin{minipage}{0.49\linewidth}
      \centering
      \includegraphics[width=\textwidth]{word2vec.png}
      \caption{а) Word2Vec}
      \label{fig:graph-word2vec}
    \end{minipage}
    \begin{minipage}{0.49\linewidth}
      \centering
      \includegraphics[width=\textwidth]{glove.png}
      \caption{б) GloVe}
      \label{fig:graph-glove}
    \end{minipage}
    \caption{Графы, полученные моделями Word2Vec и GloVe}
  \end{figure}
\end{frame}
  
% Сравнительный анализ показал, что модель GloVe демонстрирует более высокую точность в подборе семантически близких слов. В то же время Word2Vec возвращает больше нерелевантных результатов и иногда откровенно некорректные ответы.
  
\begin{frame}
  \frametitle{Расширение моделей \slnumber}
  \large
  % У модели, обученной на небольшом корпусе, возникают проблемы со слабым покрытием словаря, нестабильностью эмбеддингов и недостаточностью семантической выразительности.

  Модель \texttt{ruscorpora\_upos\_skipgram\_300\_5\_2018} и обученные модели Word2Vec и GloVe расширены по следующему алгоритму:
  \begin{enumerate}
    \item если эмбеддинг слова есть в обоих моделях, то используется среднее арифметическое векторов из обеих моделей;
    \item если эмбеддинг слова есть только в одной из моделей, в итоговой модели используется вектор из той модели, в которой он имеется.
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Получение эмбеддингов документов \slnumber}
  \large
  Эмбеддинг документа представляется как среднее эмбеддингов всех слов в тексте:
  $$
    \bar{d} = \frac{1}{n} \sum_{i = 1}^n \bar{w}_i
  $$
\end{frame}

\begin{frame}
  \frametitle{Алгоритм семантического поиска на основе корпуса
  новостей \slnumber}
  \large
  Алгоритм семантического поиска следующий:
  \begin{enumerate}
    \item \textbf{Предварительная обработка запроса} 
    % Происходит удаление знаков препинания и имён собственных, лемматизация.
    \item \textbf{Получение эмбеддинга запроса} 
    % Вектор запроса формируется как среднее арифметическое всех векторов слов запроса.
    \item \textbf{Поиск релевантных документов} 
    % Поиск осуществляется с помощью алгоритма ближайших соседей. Результатом этого этапа является список из $k$ идентификаторов новостей.
    \item \textbf{Вывод результата} 
    % По идентификаторам вычисляются заголовки новостей.
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Пример работы алгоритм семантического поиска \slnumber}
  \large
  В качестве запроса был взят заголовок одной из новостей: \textit{<<В.В. Володин поздравил СГУ с праздником Победы>>}.
  \begin{enumerate}
      \item Предварительная обработка: ['поздравить', 'сгу', 'праздник', 'победа']
      \item Эмбеддинг запроса: 
      
      [[ $0.1731391$   $0.4556614$   $0.21552482$  $0.66046524$, $\ldots$]]
      \item ID $5$ ближайших документов: 
      
      [$22160$, $2$, $29536$, $29551$, $24466$]
      \item Полученные заголовки из ID новостей:
      \begin{itemize}
          \item В.В. Володин поздравил СГУ с праздником Победы, 
          \item СГУ приглашает саратовцев в парк Победы, 
          \item Н.В. Панков поздравляет коллектив СГУ с Новым годом,
          \item В.В. Володин поздравляет коллектив СГУ с днём Великой Победы,
          \item В СГУ пришли поздравления с майскими праздниками.
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Пример работы алгоритма семантического поиска \slnumber}
  \large
  \textbf{Пример 1:}
  Запрос: \textit{Вклад ученых}
  \begin{enumerate}
    \item Ученые СГУ получили президентские гранты
    \item В.С. Анищенко присвоено звание «Основатель научной школы»
    \item Продолжается приём заявок на соискание премии Президента в области науки и инноваций
    \item Учёный СГУ отмечен медалью ордена «За заслуги перед Отечеством» II степени
    \item Фонд «БАЗИС» открыл приём заявок на конкурсы индивидуальных исследовательских грантов
  \end{enumerate}
    
\end{frame}

\begin{frame}
  \frametitle{Пример работы алгоритма семантического поиска \slnumber}
  \large
  \textbf{Пример 2:} Запрос: \textit{Бессмертный полк}
  \begin{enumerate}
    \item В СГУ открыт студенческий штаб акции «Бессмертный полк»
    \item Сегодня в ИФиЖ состоится «Праздник белых журавлей»
    \item Студенты и сотрудники СГУ стали участниками мероприятий ко Дню Победы
    \item Сотрудники и студенты могут увековечить память защитников блокадного Ленинграда
    \item Министерство молодёжной политики предлагает сделать 70 добрых дел
\end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Пример работы алгоритма семантического поиска \slnumber}
  \large
\textbf{Пример 3:}
Запрос: \textit{Чемпионат мира по программированию}
\begin{enumerate}
    \item СГУ участвует в проведении финала чемпионата ACM"=ICPC 2013
    \item Студент ИФКиС стал чемпионом России по кикбоксингу
    \item Программисты СГУ отправились на финал Чемпионата мира
    \item Профессор В.Н. Чинилов стал призёром Чемпионата России
    \item В Саратове пройдёт Неделя информатики
\end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Сравнительный анализ моделей в рамках задачи семантического поиска \slnumber}
  \large
  Для анализа создана тестовая выборка из пар: запрос "--- идентификатор новости. 
  % Cчитается, что модель успешно ответила на запрос, если релевантная новость находится в топ"=$k$ результатов.

  Запросы генерировала модель \texttt{microsoft/Phi-4-mini-instruct}.

  Пример получаемого ответа:
  \begin{enumerate}
    \item Саратовский конкурс «Сияние талантов» 2015, 
    \item Саратовский конкурс, вокалистка, поездка в Пекин, 
    \item Конкурс «Сияние талантов», Саратов, награда в Пекине.
  \end{enumerate}

  % Помимо запросов, сгенерированных с помощью LLM, были добавлены запросы, являющиеся заголовками новости.
  Объём выборки "--- $3343$.
\end{frame}

\begin{frame}
  \frametitle{Сравнительный анализ моделей в рамках задачи семантического поиска \slnumber}
  % Модель GloVe показывает более высокую точность: нужная новость оказывается на первом месте в $34\%$ запросов и входит в топ-5 в $38\%$ случаев. Для сравнения, модель Word2Vec выдаёт релевантную новость первой в $31\%$ запросов, а в топ-5 — в $35\%$.
  \begin{figure}[!ht]
    \centering
    \small
    \includegraphics[width=0.8\textwidth]{accuracy_by_model.png}
    \caption{Точность моделей Word2Vec и GloVe в задаче семантического поиска на основе корпуса новостей}
    \label{fig:search-analyse}
  \end{figure}
\end{frame}

% Описание результатов курсовой работы - обязательный слайд
\begin{frame}
    \frametitle{Вывод  \slnumber}
    \large
    % Сравнение моделей Word2Vec и GloVe показало, что GloVe справляется лучше. Это объясняется тем, что GloVe обучается на глобальной статистике, что даёт ему преимущество в понимании семантики коротких запросов.

    % Таким образом, можно сделать вывод, что использование эмбеддингов, полученных моделью GloVe, более предпочтительно для задач семантического поиска по новостным документам. Такая модель лучше улавливает смысловые связи между короткими пользовательскими запросами и содержанием новостей, что особенно важно в условиях информационного шума и вариативности формулировок.
    \begin{itemize}
      \item 
      Была разработана система поиска по корпусу новостных документов на основе эмбеддингов
      
      \item GloVe показал лучшие результаты по сравнению с Word2Vec. Это делает его более подходящим для семантического поиска по новостям, особенно при работе с короткими запросами.
    \end{itemize}
\end{frame}

% Выводы и перспектива дальнейшей работы - необязательно
% \begin{frame}
%     \frametitle{Возможные дальнейшие исследования  \slnumber}
%     \Large
%     \begin{enumerate}
%         \item Необходимо более тщательно исследовать влияние удаленности водоема от населенных пунктов на точность результатов;
%         \item Необходимо исследовать зависимость результатов измерений от породы лягушек;
%         \item Нужно изучить влияние химического состава водоема и окружающей среды на возможность получения достоверных результатов измерений.
%     \end{enumerate}
% \end{frame}


% список литературы - обязательно
% \begin{frame}
%     \frametitle{Список использованных источников  \slnumber}
%     \small
%     \begin{thebibliography}{9}
%         \setbeamertemplate{bibliography item}[article]
%     	\bibitem{Liagushki-art}
%             Д.~А.~Шабанов, С.~Н.~Литвинчук
%     		\newblock
%     		Зелёные лягушки: жизнь без правил или особый способ эволюции?
%       		\newblock\emph{Природа}. "---
%     		2010. "--- 
%     		\No~3. "---
%     		С.~29--36.
%         \setbeamertemplate{bibliography item}[online]
%         \bibitem{el-Rana-temporaria}
%             \verb"http://www.ecosystema.ru/08nature/amf/35.htm"
%             \newblock Травяная лягушка — Rana temporaria Linnaeus
%         \setbeamertemplate{bibliography item}[article]
%         \bibitem{Monte-Carlo-art}
%             N.~Metropolis, S.~Ulam
%             \newblock The Monte Carlo Method
%             \newblock \emph{J. Amer. statistical assoc.}. "---
%             2049. "--- 
%             Vol.~44, \No~247. "---
%             Pp.~335--341.
%         \setbeamertemplate{bibliography item}[book]
%         \bibitem{Monte-Carlo-book}
%             J.~M.~Hammersley, D.~C.~Handscomb
%             \newblock Monte Carlo methods
%             \newblock Methuen: 1964. "---
%             178~p.
%         \setbeamertemplate{bibliography item}[online]
%         \bibitem{el-Pi-Monte-Carlo}
%             \verb"http://habrahabr.ru/post/128454/"
%             \newblock Вычисление числа Пи методом Монте-Карло
%     \end{thebibliography}
% \end{frame}

\begin{frame}
	\begin{beamercolorbox}[ht=7ex, dp=4ex, center, shadow=true, rounded=true]{title in head/foot}
	\centerline{\LARGE{СПАСИБО ЗА ВНИМАНИЕ!}}
	\end{beamercolorbox}
\end{frame}

\end{document} 