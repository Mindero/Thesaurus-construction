{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymorphy3\n",
    "import re\n",
    "docs = pd.read_excel(\"News_SGU_31077_Processed_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'News_Id', 'News_Link', 'News_Date', 'News_Title', 'News_Text', 'News_Tokens', 'NumWords', 'NumUnicTokens']\n"
     ]
    }
   ],
   "source": [
    "print(docs.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_dev (a_in):                              # Очистка текта от тегов и специальных символов\n",
    "    x_in = re.sub(r'\\n',' ',a_in)                    # удаление символов конца строки\n",
    "    y_in = x_in.lower()                             # приведение ситоки к нижнему регистру\n",
    "    b_in = re.sub(r'&\\w+;',' ', y_in)                 # замена тегов типа'&nbsp;'  на пробел\n",
    "    d_in = re.sub(r'<[^>]*>',' ', b_in)               # удаление тегов\n",
    "    f_in = re.sub(r'www.\\w+.\\w{2,3}?',' ', d_in)      # удаление адресов веб-серверов\n",
    "#\\xad\n",
    "#–\\xa0\n",
    "    a_in = re.sub(r'\\xad','', f_in)\n",
    "    c_in = re.sub(r'\\\\xa0-','', a_in)\n",
    "    u_in = re.sub(r'\\\\u200e','', c_in)    \n",
    "    w_in = re.sub(r'\\d+','', u_in)                        # удаление последовательностей цифр\n",
    "    y_in = re.sub(r'[\\-]',' ',w_in)\n",
    "    yy_in = re.sub(r'[_]+', ' ',y_in)\n",
    "    yyy_in = re.sub(r'[ι,…,—,–,//,\\(,\\),\",\\[,\\],\\\\\\\\,\\\\,,\\-,:,;,<,>,=,©,@,№,#,%,\\',\\+,\\*,“,”,&,∙,~,\\$,\\^,•,«,»,_,ι,і,‑,‘,’,і]+','',yy_in)\n",
    "#    s_in = re.sub(r'\\W', ' ', y_in)\n",
    "    q_in = re.sub(r'[a-z]*','', yyy_in)                 # удаление латинских букв\n",
    "    \n",
    "    sss_in = re.sub(r'\\b\\w{,2}\\b','', q_in)          # удаление всех слов длиной до 2-х букв\n",
    "    qms_in = re.sub(r'\\s{2,}',' ', q_in)            # замена кратного числа пробелов на один\n",
    "    nms_in = qms_in.strip()\n",
    "#    nms_in = re.sub(r'^[^\\w]*\\s', '', qms_in)         # удаление пробелов в начале строки\n",
    "#    mms_in = re.sub(r'\\s*$','', nms_in)              # удаление пробелов в конце строки\n",
    "    return (nms_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematization (f_input_list):          # Лематизация слов в списке\n",
    "    morph = pymorphy3.MorphAnalyzer()\n",
    "    lnorm = list()\n",
    "    for word in f_input_list:\n",
    "        p = morph.parse(word)[0]\n",
    "        lnorm.append(p.normal_form)\n",
    "    return (lnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_my_stop_words(word_tokens): # удаление из списка моих стоп-слов\n",
    "    stop_words_nltk = {'который', 'кому', 'имя', 'сегодня', 'вчера', 'завтра', 'также', 'в', 'во', 'свой', \n",
    "                  'это', 'часто', 'зачастую', 'мочь', 'смочь','а', 'без', 'более', 'больше', 'будет', 'будто', \n",
    "                  'бы', 'был', 'была', 'были', 'было', 'быть', 'в', 'вам', 'вас', 'вдруг', 'ведь', 'во', 'вот', \n",
    "                  'впрочем', 'все', 'всегда', 'всего', 'всех', 'всю', 'вы', 'где', 'да', 'даже', 'два', 'для', \n",
    "                  'до', 'другой', 'его', 'ее', 'ей', 'ему', 'если', 'есть', 'еще', 'ж', 'же', 'за', 'зачем', 'здесь', \n",
    "                  'и', 'из', 'или', 'им', 'иногда', 'их', 'к', 'как', 'какая', 'какой', 'когда', 'конечно', 'кто', \n",
    "                  'куда', 'ли', 'лучше', 'между', 'меня', 'мне', 'много', 'может', 'можно', 'мой', 'моя', 'мы', 'на',\n",
    "                  'над', 'надо', 'наконец', 'нас', 'не', 'него', 'нее', 'ней', 'нельзя', 'нет', 'ни', 'нибудь', \n",
    "                  'никогда', 'ним', 'них', 'ничего', 'но', 'ну', 'о', 'об', 'один', 'он', 'она', 'они', 'опять', \n",
    "                  'от', 'перед', 'по', 'под', 'после', 'потом', 'потому', 'почти', 'при', 'про', 'раз', 'разве', \n",
    "                  'с', 'со', 'сам', 'свою', 'себе', 'себя', 'сейчас', 'c', 'со', 'совсем', 'так', 'такой', 'там', 'тебя', \n",
    "                  'тем', 'теперь', 'то', 'тогда', 'того', 'тоже', 'только', 'том', 'тот', 'три', 'тут', 'ты', \n",
    "                  'у', 'уж', 'уже', 'хорошо', 'хоть', 'что', 'чего', 'чем', 'через', 'что', 'чтоб', 'чтобы', 'чуть', \n",
    "                  'эти', 'этого', 'этой', 'этом', 'этот', 'эту', 'я', 'сказал', 'человек', 'жизнь', 'говорил', 'кажется', \n",
    "                  'сказать', 'сегодня', 'сказала', 'сказал'} \n",
    "\n",
    "    my_stop_words = {'сгт','свой', 'стать', 'кроме', 'разный', 'около', 'затем', 'помимо', 'ваш', 'вам', 'некоторый', \n",
    "                     'лишь', 'каждый', 'самый', 'также', 'неоднократно', 'ещё', 'сразу', 'среди',\n",
    "                  'однако', 'вновь', 'иной', 'ныне', 'пока', 'хотя','либо','немного', 'гораздо', 'ничто', 'нередко', 'ныне', \n",
    "                  'наоборот', 'впереди', 'таковой', 'мимо', 'тесно', 'вряд', 'нечто', 'почём', 'почему', 'любой', 'обратно',\n",
    "                  'оттуда', 'очень', 'понапрасну', 'поскольку', 'почему', 'поэтому', 'прежде', 'причём', 'прочий', 'пусть', \n",
    "                  'пока', 'это', 'наш', 'несколько', 'около', 'помимо', 'однако', 'сколько', 'либо', 'гораздо', 'ничто',\n",
    "                   'наоборот', 'никак', 'таковой', 'твой', 'нечто', 'понапрасну', 'почём', 'подробный', 'информация'}\n",
    "\n",
    "    stop_words = stop_words_nltk | my_stop_words\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsNERTagger,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "\n",
    "def remove_proper_nouns(text):\n",
    "    # Пропускаем не-строки и пустые строки\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        print(\"text имеет неожидаемый тип\")\n",
    "        return text\n",
    "    \n",
    "    try:\n",
    "        doc = Doc(text)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        doc.tag_ner(ner_tagger)\n",
    "        \n",
    "        # Если нет сущностей, возвращаем исходный текст\n",
    "        if not doc.spans:\n",
    "            return text\n",
    "        \n",
    "        # Собираем сущности для удаления\n",
    "        spans_to_remove = [span for span in doc.spans if span.type in ['PER', 'LOC', 'ORG']]\n",
    "        \n",
    "        # Если нечего удалять\n",
    "        if not spans_to_remove:\n",
    "            return text\n",
    "            \n",
    "        # Удаляем сущности (начиная с конца)\n",
    "        text_cleaned = text\n",
    "        for span in sorted(spans_to_remove, key=lambda x: x.start, reverse=True):\n",
    "            text_cleaned = text_cleaned[:span.start] + text_cleaned[span.stop:]\n",
    "            \n",
    "        return text_cleaned.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке текста: {text[:50]}... Ошибка: {str(e)}\")\n",
    "        return text  # В случае ошибки возвращаем исходный текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_str_of_the_news(string):  # Обработка сырой строки-новости \n",
    "    global abbr_list\n",
    "    string_2 = string_dev(string)     # Предобработка строки\n",
    "    \n",
    "    if len(string_2) != 0:  # Если строка непустая после обработки\n",
    "        list_of_sentences = re.split(r'[.!?]', string_2)\n",
    "        list_of_sentences = [x.split(' ') for x in list_of_sentences if x]\n",
    "        \n",
    "        filtered_sentences = []\n",
    "        for sentence in list_of_sentences:\n",
    "            no_stopwords_1 = del_my_stop_words(sentence)\n",
    "            lemmatized = lematization(no_stopwords_1)\n",
    "            no_stopwords_2 = del_my_stop_words(lemmatized)\n",
    "            text = ' '.join(no_stopwords_2)\n",
    "            # Удаление слов длиной ≤ 2 символов\n",
    "            text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
    "            # Замена нескольких пробелов на один\n",
    "            text = re.sub(r'\\s{2,}', ' ', text)\n",
    "            text = text.strip()\n",
    "            if text and len(text) > 0:\n",
    "                filtered_sentences.append(text)\n",
    "    \n",
    "    return filtered_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m docs[\u001b[33m'\u001b[39m\u001b[33mNews_Tokens\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNews_Text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_str_of_the_news\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mprocess_str_of_the_news\u001b[39m\u001b[34m(string)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m list_of_sentences:\n\u001b[32m     11\u001b[39m     no_stopwords_1 = del_my_stop_words(sentence)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     lemmatized = \u001b[43mlematization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_stopwords_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     no_stopwords_2 = del_my_stop_words(lemmatized)\n\u001b[32m     14\u001b[39m     text = \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(no_stopwords_2)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mlematization\u001b[39m\u001b[34m(f_input_list)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlematization\u001b[39m (f_input_list):          \u001b[38;5;66;03m# Лематизация слов в списке\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     morph = \u001b[43mpymorphy3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMorphAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     lnorm = \u001b[38;5;28mlist\u001b[39m()\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m f_input_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pymorphy3\\analyzer.py:215\u001b[39m, in \u001b[36mMorphAnalyzer.__init__\u001b[39m\u001b[34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m lang \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    213\u001b[39m     lang = \u001b[33m'\u001b[39m\u001b[33mru\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m path = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchoose_dictionary_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m.dictionary = opencorpora_dict.Dictionary(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pymorphy3\\analyzer.py:295\u001b[39m, in \u001b[36mMorphAnalyzer.choose_dictionary_path\u001b[39m\u001b[34m(cls, path, lang)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.DICT_PATH_ENV_VARIABLE \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m os.environ[\u001b[38;5;28mcls\u001b[39m.DICT_PATH_ENV_VARIABLE]\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlang_dict_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pymorphy3\\analyzer.py:147\u001b[39m, in \u001b[36mlang_dict_path\u001b[39m\u001b[34m(lang)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlang_dict_path\u001b[39m(lang):\n\u001b[32m    146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Return language-specific dictionary path \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     lang_paths = \u001b[43m_lang_dict_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m lang_paths:\n\u001b[32m    149\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m lang_paths[lang]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pymorphy3\\analyzer.py:132\u001b[39m, in \u001b[36m_lang_dict_paths\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_lang_dict_paths\u001b[39m():\n\u001b[32m    130\u001b[39m     paths = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    131\u001b[39m         (pkg.name, pkg.load().get_path())\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m pkg \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_iter_entry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpymorphy3_dicts\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     )\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# discovery of pymorphy3 v0.8 dicts\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vadim\\Desktop\\6 sem\\Курсовая\\.venv\\Lib\\site-packages\\pymorphy3\\analyzer.py:117\u001b[39m, in \u001b[36m_iter_entry_points\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03mFinds entry points of installed packages, including ones installed\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[33;03mafter the current process is started.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m \u001b[33;03mSee https://github.com/kmike/pymorphy2/issues/131\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m entry_points, EntryPoint\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m ep = \u001b[43mentry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m result: \u001b[38;5;28mset\u001b[39m[EntryPoint] = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ep, \u001b[33m'\u001b[39m\u001b[33mselect\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# Python < 3.10 old entry_points API\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\scoop\\apps\\python\\3.12.6\\Lib\\importlib\\metadata\\__init__.py:913\u001b[39m, in \u001b[36mentry_points\u001b[39m\u001b[34m(**params)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[32m    903\u001b[39m \n\u001b[32m    904\u001b[39m \u001b[33;03mPass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    908\u001b[39m \u001b[33;03m:return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[32m    909\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    910\u001b[39m eps = itertools.chain.from_iterable(\n\u001b[32m    911\u001b[39m     dist.entry_points \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[32m    912\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m913\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEntryPoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m.select(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\scoop\\apps\\python\\3.12.6\\Lib\\importlib\\metadata\\__init__.py:911\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mentry_points\u001b[39m(**params) -> EntryPoints:\n\u001b[32m    902\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[32m    903\u001b[39m \n\u001b[32m    904\u001b[39m \u001b[33;03m    Pass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    908\u001b[39m \u001b[33;03m    :return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[32m    909\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    910\u001b[39m     eps = itertools.chain.from_iterable(\n\u001b[32m--> \u001b[39m\u001b[32m911\u001b[39m         \u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mentry_points\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[32m    912\u001b[39m     )\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints(eps).select(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\scoop\\apps\\python\\3.12.6\\Lib\\importlib\\metadata\\__init__.py:471\u001b[39m, in \u001b[36mDistribution.entry_points\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    469\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mentry_points\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints._from_text_for(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mentry_points.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\scoop\\apps\\python\\3.12.6\\Lib\\importlib\\metadata\\__init__.py:819\u001b[39m, in \u001b[36mPathDistribution.read_text\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    811\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[32m    812\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\n\u001b[32m    813\u001b[39m         \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m,\n\u001b[32m    814\u001b[39m         \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    817\u001b[39m         \u001b[38;5;167;01mPermissionError\u001b[39;00m,\n\u001b[32m    818\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m819\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\scoop\\apps\\python\\3.12.6\\Lib\\pathlib.py:1028\u001b[39m, in \u001b[36mPath.read_text\u001b[39m\u001b[34m(self, encoding, errors)\u001b[39m\n\u001b[32m   1026\u001b[39m encoding = io.text_encoding(encoding)\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.open(mode=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=encoding, errors=errors) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:319\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "docs['News_Tokens'] = docs[\"News_Text\"].apply(process_str_of_the_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['май состояться общенародный акция бессмертный полк принять участие студент сотрудник сгу', 'год ограничение пандемия долгожданный шествие проходить традиционный формат', 'время построение колонна корпус саратовский университет студенческий клуб задавать настроение концертный программа', 'звучать песня военный год исполнить студент участник вокальный ансамбль сгу', 'зритель узнавать горячо любимый песня подпевать дарить аплодисменты', 'вокальный номер перемежаться танцевальный', 'ансамбль современный хореография анатолий тимофеев представить выступление отразить многонациональность культурный многообразие россия', 'пересечение улица астраханский московский колонна бессмертный полка начало движение мелодичный звук оркестр', 'участник акция бережно нести портрет родственник приближать победа поле бой тыл портрет пасть герой великий отечественный война прадед дед отвоевать мир следующий поколение', 'делиться радость петь песня смуглянка катюша синий платочек воодушевлённо кричать ура', 'шествие принять участие ректор саратовский университет', 'чумаченко проректор сотрудник преподаватель студент саратовский университет', 'алексей николаевич отметить особый энергетика бессмертный полка идея акция прийти сверху снизу полностью создать добровольный начало', 'приходить воля делиться эмоция', 'посмотреть лицо участник шествие радостный всё помнить', 'помнить уйти родственник живой сердце день вместе', 'слово алексей николаевич шествие бессмертный полка узнавать российский солдат принимать участие военный спецоперация уверенный акция поднять боевой дух', 'шествие традиционно завершиться театральный площадь горожанин встречать концертный программа свет великий победа', 'участие концерт принять артист студклуб сгу', 'данные организатор год бессмертный полк саратов прислать тысяча']\n"
     ]
    }
   ],
   "source": [
    "docs['News_Tokens'] = docs['News_Tokens'].apply(\n",
    "    lambda sentence_list: [remove_proper_nouns(sent) for sent in sentence_list]\n",
    ")\n",
    "docs.to_csv(\"data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
